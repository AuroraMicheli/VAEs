{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64         # number of data points in each batch\n",
    "N_EPOCHS = 10           # times to run the model on complete data\n",
    "INPUT_DIM = 28 * 28     # size of each input\n",
    "HIDDEN_DIM = 256        # hidden dimension\n",
    "LATENT_DIM = 50         # latent vector dimension\n",
    "lr = 1e-3               # learning rate\n",
    "\n",
    "transforms = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.MNIST(\n",
    "    './data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms)\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    './data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms\n",
    ")\n",
    "\n",
    "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_iterator = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    ''' This is the encoder part of VAE\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, z_dim):\n",
    "        '''\n",
    "        Args:\n",
    "            input_dim: An integer indicating the size of the input (in case of MNIST 28 * 28).\n",
    "            hidden_dim: An integer indicating the size of the hidden dimension.\n",
    "            z_dim: An integer indicating the latent dimension.\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Linear(input_dim, hidden_dim)\n",
    "        self.mu = nn.Linear(hidden_dim, z_dim)\n",
    "        self.var = nn.Linear(hidden_dim, z_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, input_dim]\n",
    "\n",
    "        hidden = F.relu(self.linear(x))\n",
    "        # hidden is of shape [batch_size, hidden_dim]\n",
    "        z_mu = self.mu(hidden)\n",
    "        # z_mu is of shape [batch_size, latent_dim]\n",
    "        z_var = self.var(hidden)\n",
    "        # z_var is of shape [batch_size, latent_dim]\n",
    "\n",
    "        return z_mu, z_var\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 160.38, Test Loss: 130.08\n",
      "Epoch 1, Train Loss: 123.73, Test Loss: 117.78\n",
      "Epoch 2, Train Loss: 115.43, Test Loss: 112.31\n",
      "Epoch 3, Train Loss: 111.90, Test Loss: 109.91\n",
      "Epoch 4, Train Loss: 110.02, Test Loss: 108.89\n",
      "Epoch 5, Train Loss: 108.90, Test Loss: 107.67\n",
      "Epoch 6, Train Loss: 108.08, Test Loss: 107.25\n",
      "Epoch 7, Train Loss: 107.53, Test Loss: 106.74\n",
      "Epoch 8, Train Loss: 107.08, Test Loss: 106.70\n",
      "Epoch 9, Train Loss: 106.71, Test Loss: 106.00\n"
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    ''' This is the decoder part of VAE\n",
    "    '''\n",
    "    def __init__(self, z_dim, hidden_dim, output_dim):\n",
    "        '''\n",
    "        Args:\n",
    "            z_dim: An integer indicating the latent size.\n",
    "            hidden_dim: Ann integer indicating the size of the hidden dimension.\n",
    "            output_dim: A integer indicating the output dimension (in case of MNIST it is 28 * 28)\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Linear(z_dim, hidden_dim)\n",
    "        self.out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, latent_dim]\n",
    "\n",
    "        hidden = F.relu(self.linear(x))\n",
    "        # hidden is of shape [batch_size, hidden_dim]\n",
    "\n",
    "        predicted = torch.sigmoid(self.out(hidden))\n",
    "        # predicted is of shape [batch_size, output_dim]\n",
    "        return predicted\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, enc, dec):\n",
    "        ''' This is the VAE, which takes an encoder and a decoder.\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.enc = enc\n",
    "        self.dec = dec\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encode\n",
    "        z_mu, z_var = self.enc(x)\n",
    "\n",
    "        # sample from the distribution having latent parameters z_mu, z_var\n",
    "        # reparameterize\n",
    "        std = torch.exp(z_var / 2)\n",
    "        eps = torch.randn_like(std)\n",
    "        x_sample = eps.mul(std).add_(z_mu)\n",
    "\n",
    "        # decode\n",
    "        predicted = self.dec(x_sample)\n",
    "        return predicted, z_mu, z_var\n",
    "\n",
    "# encoder\n",
    "encoder = Encoder(INPUT_DIM, HIDDEN_DIM, LATENT_DIM)\n",
    "\n",
    "# decoder\n",
    "decoder = Decoder(LATENT_DIM, HIDDEN_DIM, INPUT_DIM)\n",
    "\n",
    "# vae\n",
    "model = VAE(encoder, decoder).to(device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "def train():\n",
    "    # set the train mode\n",
    "    model.train()\n",
    "\n",
    "    # loss of the epoch\n",
    "    train_loss = 0\n",
    "\n",
    "    for i, (x, _) in enumerate(train_iterator):\n",
    "        # reshape the data into [batch_size, 784]\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = x.to(device)\n",
    "\n",
    "        # update the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        x_sample, z_mu, z_var = model(x)\n",
    "\n",
    "        # reconstruction loss\n",
    "        recon_loss = F.binary_cross_entropy(x_sample, x, size_average=False)\n",
    "\n",
    "        # kl divergence loss\n",
    "        kl_loss = 0.5 * torch.sum(torch.exp(z_var) + z_mu**2 - 1.0 - z_var)\n",
    "\n",
    "        # total loss\n",
    "        loss = recon_loss + kl_loss\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def test():\n",
    "    # set the evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # test loss for the data\n",
    "    test_loss = 0\n",
    "\n",
    "    # we don't need to track the gradients, since we are not updating the parameters during evaluation / testing\n",
    "    with torch.no_grad():\n",
    "        for i, (x, _) in enumerate(test_iterator):\n",
    "            # reshape the data\n",
    "            x = x.view(-1, 28 * 28)\n",
    "            x = x.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            x_sample, z_mu, z_var = model(x)\n",
    "\n",
    "            # reconstruction loss\n",
    "            recon_loss = F.binary_cross_entropy(x_sample, x, size_average=False)\n",
    "\n",
    "            # kl divergence loss\n",
    "            kl_loss = 0.5 * torch.sum(torch.exp(z_var) + z_mu**2 - 1.0 - z_var)\n",
    "\n",
    "            # total loss\n",
    "            loss = recon_loss + kl_loss\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    return test_loss\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "\n",
    "for e in range(N_EPOCHS):\n",
    "\n",
    "    train_loss = train()\n",
    "    test_loss = test()\n",
    "\n",
    "    train_loss /= len(train_dataset)\n",
    "    test_loss /= len(test_dataset)\n",
    "\n",
    "    print(f'Epoch {e}, Train Loss: {train_loss:.2f}, Test Loss: {test_loss:.2f}')\n",
    "\n",
    "    if best_test_loss > test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        patience_counter = 1\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter > 3:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x247b188a490>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sample and generate a image\n",
    "z = torch.randn(1, LATENT_DIM).to(device)\n",
    "\n",
    "# run only the decoder\n",
    "reconstructed_img = model.dec(z)\n",
    "img = reconstructed_img.view(28, 28).data.cpu()\n",
    "\n",
    "print(z.shape)\n",
    "print(img.shape)\n",
    "\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "21f70cf4e8d561a50197189da02bc4da5d9293f6b358ed57b87ee5706fd96cf1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
